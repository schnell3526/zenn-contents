---
title: "huggingface Tokenizers"
emoji: "😽"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["自然言語処理","形態素解析", "Python"]
published: false
---
[Tokenizers](https://huggingface.co/docs/tokenizers/index)はHugging Face社が開発するニューラル自然言語処理向けのテキスト分割器(tokenizer)のライブラリです。自前でtokenizerのカスタマイズができる上にrust実装で高速に動作するのが魅力です。

一方で、同じみの[Transformers](https://huggingface.co/docs/transformers/index)ではモデルとtokenizerが同梱されて利用できるようになっております。学習済みモデルを利用する際には同梱されていると便利ですので、Tokenizersで学習したtokenizerをTransformersのAPIで使えるようにします。
~~Huggig faceはライブラリに一般名を付けるのをやめてほしい。。~~

# Tokenizersでtokenizerの学習を行う
まずはTokenizersライブラリでtokenizerをカスタムします。